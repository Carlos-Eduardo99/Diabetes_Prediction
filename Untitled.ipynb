{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d752fd3",
   "metadata": {},
   "source": [
    "# Tópicos Especiais em Engenharia de Computação"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c38845",
   "metadata": {},
   "source": [
    "## Trabalho Final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c71eb8",
   "metadata": {},
   "source": [
    "## Diabetes prediction dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc71126",
   "metadata": {},
   "source": [
    "### Carlos Eduardo de Sousa\n",
    "### Denilson Aparecido de Morais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15f7c20",
   "metadata": {},
   "source": [
    "## 1. Preparação do ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c574990f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#funcao para deixar o jupyter com celulas preenchendo toda a tela\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1720a3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.4.0 (SDL 2.26.4, Python 3.10.9)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-23 08:15:00.389327: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#importacao de bibliotecas\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#bibliotecas para trabalhar com dados e graficos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "\n",
    "#bibliotecas do scikit-learn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#biblioteca para exportacoes e importacoes de arquivos\n",
    "from joblib import dump, load\n",
    "\n",
    "#biblioteca para implementar uma barra de progresso\n",
    "import progressbar\n",
    "\n",
    "#biblioteca para tocar sons\n",
    "import pygame\n",
    "\n",
    "#bibliotecas para deep learning\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Input, LayerNormalization, BatchNormalization, Flatten, Dense, Reshape, Dropout\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import BinaryCrossentropy\n",
    "from tensorflow.keras.activations import softmax\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "#bibliotecas para plotar graficos do keras\n",
    "import pydot as pyd\n",
    "import pydotplus\n",
    "from pydotplus import graphviz\n",
    "from tensorflow.keras.utils import plot_model, model_to_dot\n",
    "tensorflow.keras.utils.pydot = pyd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19e71b6",
   "metadata": {},
   "source": [
    "## 2. Importações de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d716061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5244/3991910836.py:6: DtypeWarning: Columns (1,2,3,5,6,7,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('/home/carlos/Área de Trabalho/Faculdade/Tópicos Especiais em Engenharia de Computação/Trabalho Final/dataset/diabetes_prediction_dataset.csv', header=None, names=col_names)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender                 0\n",
      "age                    0\n",
      "hypertension           0\n",
      "heart_disease          0\n",
      "smoking_history        0\n",
      "bmi                    0\n",
      "HbA1c_level            0\n",
      "blood_glucose_level    0\n",
      "diabetes               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "col_names = ['gender', 'age', 'hypertension', 'heart_disease',\n",
    "                'smoking_history', 'bmi', 'HbA1c_level', 'blood_glucose_level',\n",
    "                'diabetes']\n",
    "\n",
    "#importacao de dados\n",
    "data = pd.read_csv('/home/carlos/Área de Trabalho/Faculdade/Tópicos Especiais em Engenharia de Computação/Trabalho Final/dataset/diabetes_prediction_dataset.csv', header=None, names=col_names)\n",
    "\n",
    "# Remover a primeira linha do dataset\n",
    "data = data.iloc[1:]\n",
    "\n",
    "# Verificar se o dataset apresenta valores ausentes\n",
    "missing_values = data.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e5e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo os tipos de classificações para os dados \"smoking history\"\n",
    "smoking_classifications = data['smoking_history'].unique()\n",
    "class_smoking = len(smoking_classifications)\n",
    "\n",
    "print(smoking_classifications)\n",
    "print(class_smoking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b914b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtendo os tipos de classificações para os dados \"gender\"\n",
    "gender_classifications = data['gender'].unique()\n",
    "class_gender = len(gender_classifications)\n",
    "\n",
    "print(gender_classifications)\n",
    "print(class_gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7c2628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapear as classes de 'smoking_history' para valores numéricos\n",
    "le = LabelEncoder()\n",
    "data['smoking_history'] = le.fit_transform(data['smoking_history'])\n",
    "\n",
    "# Aplicar o one-hot encoding na coluna 'smoking_history'\n",
    "smoking_encoded = to_categorical(data['smoking_history'], num_classes=class_smoking)\n",
    "data['smoking_history'] = smoking_encoded\n",
    "\n",
    "# Mapear as classes de 'gender' para valores numéricos\n",
    "le = LabelEncoder()\n",
    "data['gender'] = le.fit_transform(data['gender'])\n",
    "\n",
    "# Aplicar o one-hot encoding na coluna 'gender'\n",
    "gender_encoded = to_categorical(data['gender'], num_classes=class_gender)\n",
    "data['gender'] = gender_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7340d43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converte os dados para numérico\n",
    "\n",
    "data['age'] = data['age'].astype(float)\n",
    "data['bmi'] = data['bmi'].astype(float)\n",
    "data['HbA1c_level'] = data['HbA1c_level'].astype(float)\n",
    "\n",
    "data['hypertension'] = data['hypertension'].astype(float)\n",
    "data['heart_disease'] = data['heart_disease'].astype(float)\n",
    "data['blood_glucose_level'] = data['blood_glucose_level'].astype(float)\n",
    "data['diabetes'] = data['diabetes'].astype(float)\n",
    "\n",
    "#nomeia as entradas\n",
    "x_names = data.columns[:-1].tolist()\n",
    "y_names = data.columns[-1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36cceee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddeb45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(smoking_encoded[0]) #never\n",
    "print(smoking_encoded[1]) #No info\n",
    "print(smoking_encoded[3]) #current\n",
    "print(smoking_encoded[12]) #former\n",
    "print(smoking_encoded[26]) #not current\n",
    "print(smoking_encoded[88]) #ever\n",
    "\n",
    "print(gender_encoded[12669]) #Other\n",
    "print(gender_encoded[0]) #Female\n",
    "print(gender_encoded[2]) #Male"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8d6b2d",
   "metadata": {},
   "source": [
    "## 3. Configurações do experimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1acfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#realizar deteccao e substituicao de outliers\n",
    "outliers_exec = True\n",
    "\n",
    "#realizar normalizacao de dados\n",
    "normalization_exec = True\n",
    "\n",
    "#realizar escalonamento de dados\n",
    "scale_exec = True\n",
    "\n",
    "#exportar os datasets tratados\n",
    "export_frames = True\n",
    "\n",
    "#gerar um novo modelo ou usar um pronto\n",
    "new_model = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e575973",
   "metadata": {},
   "source": [
    "## 4. Análise de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b60be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conta os diagnosticos\n",
    "diagnosis_counts = data['diabetes'].value_counts()\n",
    "\n",
    "#plota o grafico\n",
    "plt.figure(figsize=(6, 6))\n",
    "diagnosis_counts.plot(kind='bar')\n",
    "plt.xlabel('Diagnóstico')\n",
    "plt.ylabel('Contagem')\n",
    "plt.title('Contagem de Tipos de Diagnóstico')\n",
    "\n",
    "#adiciona os rotulos\n",
    "for i, count in enumerate(diagnosis_counts):\n",
    "    plt.text(i, count, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec888723",
   "metadata": {},
   "source": [
    "### 4.1 Sumarização estatística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610b7f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumarizacao(data):\n",
    "    stats = []\n",
    "\n",
    "    for column in ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']:\n",
    "        values = data[column]\n",
    "\n",
    "        maximum = round(values.max(), 2)\n",
    "        minimum = round(values.min(), 2)\n",
    "        mean = round(values.mean(), 2)\n",
    "        median = round(values.median(), 2)\n",
    "        std = round(values.std(), 2)\n",
    "        stats.append([column, maximum, minimum, mean, median, std])\n",
    "\n",
    "    headers = ['Coluna', 'Máximo', 'Mínimo', 'Média', 'Mediana', 'Desvio Padrão']\n",
    "\n",
    "    table = tabulate(stats, headers, tablefmt=\"pipe\")\n",
    "    print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71afda48",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumarizacao(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22302bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(9, 9), tight_layout=True)\n",
    "\n",
    "for i, atributo in enumerate(x_names):\n",
    "    row = i // 3  # Linha atual\n",
    "    col = i % 3   # Coluna atual\n",
    "    axs[row, col].hist(data[atributo], bins=10)\n",
    "    axs[row, col].set_title(atributo)\n",
    "    axs[row, col].set_xlabel('Valores')\n",
    "    axs[row, col].set_ylabel('Frequência')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac09a108",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = ['bmi', 'HbA1c_level', 'blood_glucose_level']\n",
    "\n",
    "data.boxplot(column=columns_to_plot, by='diabetes', figsize=(12, 12))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c95c68",
   "metadata": {},
   "source": [
    "### 4.2 Tratando outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a8d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getQuantiles(x, margin = 1.5, low = 0.1, high = 0.9):\n",
    "    q1 = x.quantile(low)\n",
    "    q3 = x.quantile(high)\n",
    "    iqr = q3-q1\n",
    "\n",
    "    fence_low  = q1 - margin * iqr\n",
    "    fence_high = q3 + margin * iqr\n",
    "    \n",
    "    return [fence_low, fence_high]\n",
    "    \n",
    "def replaceOutliers(serie, m):\n",
    "    x = serie.copy()\n",
    "    \n",
    "    fences = getQuantiles(x, margin = m)\n",
    "\n",
    "    bad_inds = x.loc[(x < fences[0]) | (x > fences[1])].index\n",
    "    \n",
    "    x[bad_inds] = np.nan\n",
    "    \n",
    "    outlier_inds_danger = [0, 1, len(serie) - 2, len(serie) - 1]\n",
    "\n",
    "    for ind_danger in outlier_inds_danger:\n",
    "        if np.isnan(x.iloc[ind_danger]):\n",
    "            x[ind_danger] = (fences[0] + fences[1])/2\n",
    "\n",
    "    if x.isnull().values.any():\n",
    "        x = x.interpolate(method='nearest').copy()\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b081811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if outliers_exec:\n",
    "    for col in x_names:\n",
    "        if col in ['bmi', 'HbA1c_level', 'blood_glucose_level']:\n",
    "            data[col] = replaceOutliers(data[col], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20768ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = ['bmi', 'HbA1c_level', 'blood_glucose_level']\n",
    "\n",
    "data.boxplot(column=columns_to_plot, by='diabetes', figsize=(12, 12))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40351c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumarizacao(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc8c4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(9, 9), tight_layout=True)\n",
    "\n",
    "for i, atributo in enumerate(x_names):\n",
    "    row = i // 3  # Linha atual\n",
    "    col = i % 3   # Coluna atual\n",
    "    axs[row, col].hist(data[atributo], bins=10)\n",
    "    axs[row, col].set_title(atributo)\n",
    "    axs[row, col].set_xlabel('Valores')\n",
    "    axs[row, col].set_ylabel('Frequência')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d174c520",
   "metadata": {},
   "source": [
    "### 4.3 Aplicando normalizacao (estabilização de variância)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f655e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def varianceEstabilization(serie, method):\n",
    "    if method == 'asinh':\n",
    "        return np.arcsinh(serie)\n",
    "    elif method == 'log':\n",
    "        return np.log(serie)\n",
    "    elif method == 'mean':\n",
    "        return (serie - np.mean(serie))/np.std(serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15f1ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if normalization_exec:\n",
    "    for col in x_names:\n",
    "        data[col] = varianceEstabilization(data[col], 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c084ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a0a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 3, figsize=(9, 9), tight_layout=True)\n",
    "\n",
    "for i, atributo in enumerate(x_names):\n",
    "    row = i // 3  # Linha atual\n",
    "    col = i % 3   # Coluna atual\n",
    "    axs[row, col].hist(data[atributo], bins=10)\n",
    "    axs[row, col].set_title(atributo)\n",
    "    axs[row, col].set_xlabel('Valores')\n",
    "    axs[row, col].set_ylabel('Frequência')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396fac13",
   "metadata": {},
   "source": [
    "### 4.5 Exportando ou carregando um dataset tratado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96ef37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if export_frames == True:\n",
    "    bar = progressbar.ProgressBar(maxval=len(data), widgets=[progressbar.Bar(\"=\", \"[\", \"]\"), \" \", progressbar.Percentage()])\n",
    "    bar.start()\n",
    "\n",
    "    x_frames = []\n",
    "    y_frames = []\n",
    "    \n",
    "    data = data.reset_index(drop=True)  # Redefinir o índice do DataFrame\n",
    "    \n",
    "    cont = 0\n",
    "    for ind in range(0, len(data), 1):\n",
    "        x_frames.append(data.loc[ind, x_names].values)\n",
    "        y_frames.append(data.loc[ind, y_names].values)\n",
    "        \n",
    "        bar.update(cont + 1)\n",
    "        cont += 1\n",
    "        \n",
    "    x_frames = np.array(x_frames)\n",
    "    y_frames = np.array(y_frames)\n",
    "    \n",
    "    dump(x_frames, 'dataset/x_frames.joblib')\n",
    "    dump(y_frames, 'dataset/y_frames.joblib')\n",
    "\n",
    "    bar.finish()\n",
    "else:\n",
    "    x_frames = load('dataset/x_frames.joblib')\n",
    "    y_frames = load('dataset/y_frames.joblib')\n",
    "\n",
    "print(x_frames.shape)\n",
    "print(y_frames.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecebf65",
   "metadata": {},
   "source": [
    "## 5. Separacao dos conjuntos de dados (treino, validação e teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9964a2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_val, x_test, y_train_val, y_test = train_test_split(x_frames, y_frames, test_size=0.3, shuffle=True)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val, y_train_val, test_size=0.3, shuffle=True)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38936489",
   "metadata": {},
   "source": [
    "## 6. Treinamento do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dad6634",
   "metadata": {},
   "source": [
    "### 6.1 Construção do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4eeb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Empilhamento de camadas para construir uma Deep Neural Network\n",
    "\n",
    "act_function = 'sigmoid'\n",
    "drop = 0.1\n",
    "initializer = tensorflow.keras.initializers.LecunNormal()\n",
    "\n",
    "inputs = Input(shape = (x_train.shape[1]), dtype='float32')\n",
    "\n",
    "layer1 = Dense(32, activation=act_function, kernel_initializer=initializer)(inputs)\n",
    "layer1 = Dropout(drop)(layer1)\n",
    "layer1 = BatchNormalization()(layer1)\n",
    "\n",
    "layer2 = Dense(64, activation=act_function, kernel_initializer=initializer)(layer1)\n",
    "layer2 = Dropout(drop)(layer2)\n",
    "layer2 = BatchNormalization()(layer2)\n",
    "\n",
    "layer3 = Dense(32, activation=act_function, kernel_initializer=initializer)(layer2)\n",
    "layer3 = Dropout(drop)(layer3)\n",
    "layer3 = BatchNormalization()(layer3)\n",
    "\n",
    "outputs = Dense(y_train.shape[1], activation=act_function, kernel_initializer=initializer)(layer3)\n",
    "\n",
    "#geracao do modelo\n",
    "dnn_diabetes_prediction = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a72759",
   "metadata": {},
   "source": [
    "### 6.2 Inspecionando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnn_diabetes_prediction.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988cef7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(dnn_diabetes_prediction, show_shapes=True, show_layer_names=True, rankdir=\"LR\")  #TB para plotar na vertical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059b9d01",
   "metadata": {},
   "source": [
    "### 6.3 Otimização do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d098f4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (new_model == True):\n",
    "    \n",
    "    tensorflow.keras.backend.set_epsilon(1)\n",
    "    opt = Adam(learning_rate=0.0001)\n",
    "    \n",
    "    dnn_diabetes_prediction.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    cp = ModelCheckpoint(\n",
    "    filepath='models/',\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n",
    "    \n",
    "    es = EarlyStopping(monitor='loss', mode='min', patience=100)\n",
    "\n",
    "    history = dnn_diabetes_prediction.fit(x_train, y_train, \n",
    "                                validation_data=(x_val, y_val), \n",
    "                                epochs=1000, \n",
    "                                verbose=1, \n",
    "                                callbacks=[es, cp], \n",
    "                                batch_size=32, \n",
    "                                shuffle=False)\n",
    "    \n",
    "    np.save('models/history_model.npy', history.history)\n",
    "    dnn_breast_cancer.load_weights('models/')\n",
    "    dnn_breast_cancer.save('models/dnn_diabetes_prediction.h5')\n",
    "else:\n",
    "    dnn_breast_cancer = load_model('models/dnn_diabetes_prediction.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e1790",
   "metadata": {},
   "source": [
    "### 6.4 Avaliação do modelo com curva de convergência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ea1426",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=np.load('models/history_model.npy', allow_pickle='TRUE').item()\n",
    "\n",
    "sns.set(rc={'figure.figsize':(12, 6)})\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('paper')\n",
    "\n",
    "train_metric = history['loss']\n",
    "valid_metric = history['val_loss']\n",
    "name_metric = 'mse'\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "plt.plot(train_metric, label='train'), \n",
    "plt.plot(valid_metric, label='validation')\n",
    "plt.ylabel(name_metric)\n",
    "plt.xlabel('epoch')\n",
    "plt.title('train vs. validation accuracy using ' + name_metric)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, ncol=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9585b76",
   "metadata": {},
   "source": [
    "## 7. Testando as previsões"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd08f3ae",
   "metadata": {},
   "source": [
    "### 7.1 Gerando as previsões com o modelo treinado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ec660",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = dnn_breast_cancer.predict(x_test)\n",
    "y_hat, y_test = (y_hat > 0.5, y_test > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc67b346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculando a matriz de confusao\n",
    "cm = confusion_matrix(y_test.tolist(), y_hat.tolist())\n",
    "\n",
    "#calculando a taxa de acerto\n",
    "accuracy = (cm[0, 0] + cm[1, 1]) / cm.sum()\n",
    "accuracy_percent = round(accuracy * 100, 2)\n",
    "print(\"Taxa de Acerto: {:.2f}%\".format(accuracy_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257733c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.grid(False)\n",
    "plt.imshow(cm, cmap='Blues')\n",
    "\n",
    "plt.xlabel('Predito', fontsize=12)\n",
    "plt.ylabel('Real', fontsize=12)\n",
    "\n",
    "threshold = cm.max() / 2.0\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        color = 'white' if cm[i, j] > threshold else 'black'\n",
    "        plt.text(j, i, str(cm[i, j]), ha='center', va='center', color=color, fontsize=12)\n",
    "\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700bf414",
   "metadata": {},
   "outputs": [],
   "source": [
    "#toca um som para avisar que terminou de executar\n",
    "pygame.mixer.init()\n",
    "arquivo_mp3 = 'support_files/mario_coin.mp3'\n",
    "pygame.mixer.music.load(arquivo_mp3)\n",
    "pygame.mixer.music.play()\n",
    "\n",
    "while pygame.mixer.music.get_busy():\n",
    "    continue\n",
    "    \n",
    "print('Sucess!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac634ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
